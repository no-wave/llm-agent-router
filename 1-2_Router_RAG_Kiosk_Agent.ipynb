{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Router RAG Agent - 커피 키오스크 주문 시스템"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정 및 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# .env 파일에서 환경 변수를 로드한다\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 설치\n",
    "%pip install -q openai pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import List, Dict, Optional, Literal\n",
    "from datetime import datetime\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field, validator\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# OpenAI 클라이언트 초기화\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pydantic 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v9/46y9d8bn1lxgjt7g439hsf8c0000gn/T/ipykernel_92317/1354236395.py:30: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  @validator('scores')\n"
     ]
    }
   ],
   "source": [
    "class RouteClassification(BaseModel):\n",
    "    \"\"\"라우터가 질문을 분류한 결과를 표현하는 모델\"\"\"\n",
    "    route_type: Literal[\"menu\", \"recipe\", \"price\"] = Field(\n",
    "        description=\"질문의 유형: menu(메뉴 정보), recipe(레시피 정보), price(가격/프로모션)\"\n",
    "    )\n",
    "    confidence: float = Field(\n",
    "        ge=0.0, le=1.0,\n",
    "        description=\"분류에 대한 신뢰도 (0.0 ~ 1.0)\"\n",
    "    )\n",
    "    reasoning: str = Field(\n",
    "        description=\"해당 라우트로 분류한 이유\"\n",
    "    )\n",
    "\n",
    "\n",
    "class DocumentChunk(BaseModel):\n",
    "    \"\"\"RAG 데이터베이스의 문서 청크를 표현하는 모델\"\"\"\n",
    "    id: str = Field(description=\"문서 청크의 고유 ID\")\n",
    "    content: str = Field(description=\"문서 청크의 내용\")\n",
    "    category: str = Field(description=\"문서가 속한 카테고리\")\n",
    "    metadata: Dict = Field(default_factory=dict, description=\"추가 메타데이터\")\n",
    "    embedding: Optional[List[float]] = Field(default=None, description=\"문서의 임베딩 벡터\")\n",
    "\n",
    "\n",
    "class RetrievalResult(BaseModel):\n",
    "    \"\"\"검색 결과를 표현하는 모델\"\"\"\n",
    "    chunks: List[DocumentChunk] = Field(description=\"검색된 문서 청크 목록\")\n",
    "    scores: List[float] = Field(description=\"각 청크의 유사도 점수\")\n",
    "    query: str = Field(description=\"원본 검색 쿼리\")\n",
    "    \n",
    "    @validator('scores')\n",
    "    def validate_scores_length(cls, v, values):\n",
    "        \"\"\"검색 점수와 청크의 개수가 일치하는지 검증한다\"\"\"\n",
    "        if 'chunks' in values and len(v) != len(values['chunks']):\n",
    "            raise ValueError(\"검색 점수와 청크의 개수가 일치해야 한다\")\n",
    "        return v\n",
    "\n",
    "\n",
    "class ConversationMessage(BaseModel):\n",
    "    \"\"\"대화 메시지를 표현하는 모델\"\"\"\n",
    "    role: Literal[\"user\", \"assistant\", \"system\"] = Field(description=\"메시지 역할\")\n",
    "    content: str = Field(description=\"메시지 내용\")\n",
    "    timestamp: datetime = Field(default_factory=datetime.now, description=\"메시지 생성 시간\")\n",
    "    metadata: Dict = Field(default_factory=dict, description=\"추가 메타데이터\")\n",
    "\n",
    "\n",
    "class AgentResponse(BaseModel):\n",
    "    \"\"\"에이전트의 최종 응답을 표현하는 모델\"\"\"\n",
    "    answer: str = Field(description=\"사용자에게 제공되는 답변\")\n",
    "    route_used: str = Field(description=\"사용된 라우트\")\n",
    "    sources: List[str] = Field(description=\"답변 생성에 사용된 소스 문서 ID\")\n",
    "    confidence: float = Field(ge=0.0, le=1.0, description=\"답변에 대한 신뢰도\")\n",
    "    validation_passed: bool = Field(description=\"검증 통과 여부\")\n",
    "    feedback_score: Optional[float] = Field(default=None, description=\"피드백 점수\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RAG 지식 베이스 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 11개의 문서 청크가 로드되었다.\n",
      "메뉴 정보: 4개\n",
      "레시피 정보: 3개\n",
      "가격 정보: 4개\n"
     ]
    }
   ],
   "source": [
    "# 메뉴 정보 지식 베이스\n",
    "MENU_KNOWLEDGE = [\n",
    "    DocumentChunk(\n",
    "        id=\"menu_001\",\n",
    "        content=\"아메리카노는 에스프레소에 물을 추가한 커피로, 진하고 깊은 맛이 특징이다. HOT과 ICE 옵션이 있다.\",\n",
    "        category=\"menu\",\n",
    "        metadata={\"beverage_type\": \"coffee\", \"has_caffeine\": True}\n",
    "    ),\n",
    "    DocumentChunk(\n",
    "        id=\"menu_002\",\n",
    "        content=\"카페라떼는 에스프레소에 스팀 밀크를 넣은 커피로, 부드럽고 크리미한 맛이 특징이다. 우유의 비율이 높아 커피가 부담스러운 사람에게 적합하다.\",\n",
    "        category=\"menu\",\n",
    "        metadata={\"beverage_type\": \"coffee\", \"has_caffeine\": True, \"contains_milk\": True}\n",
    "    ),\n",
    "    DocumentChunk(\n",
    "        id=\"menu_003\",\n",
    "        content=\"카푸치노는 에스프레소, 스팀 밀크, 우유 거품이 1:1:1 비율로 구성된 커피다. 풍부한 거품과 고소한 맛이 특징이다.\",\n",
    "        category=\"menu\",\n",
    "        metadata={\"beverage_type\": \"coffee\", \"has_caffeine\": True, \"contains_milk\": True}\n",
    "    ),\n",
    "    DocumentChunk(\n",
    "        id=\"menu_004\",\n",
    "        content=\"녹차라떼는 고품질 녹차 파우더와 우유를 블렌딩한 음료로, 녹차의 은은한 향과 우유의 부드러움이 조화롭다. 카페인이 적어 부담없이 즐길 수 있다.\",\n",
    "        category=\"menu\",\n",
    "        metadata={\"beverage_type\": \"tea\", \"has_caffeine\": True, \"contains_milk\": True}\n",
    "    )\n",
    "]\n",
    "\n",
    "# 레시피 정보 지식 베이스\n",
    "RECIPE_KNOWLEDGE = [\n",
    "    DocumentChunk(\n",
    "        id=\"recipe_001\",\n",
    "        content=\"아메리카노 레시피: 에스프레소 샷 2개를 추출한 후 물 150ml를 추가한다. ICE 아메리카노의 경우 얼음을 먼저 넣고 에스프레소와 물을 추가한다.\",\n",
    "        category=\"recipe\",\n",
    "        metadata={\"difficulty\": \"easy\", \"prep_time\": \"2분\"}\n",
    "    ),\n",
    "    DocumentChunk(\n",
    "        id=\"recipe_002\",\n",
    "        content=\"카페라떼 레시피: 에스프레소 샷 2개를 추출하고, 우유 200ml를 스티밍하여 에스프레소에 부드럽게 붓는다. 우유 온도는 65-70도가 적절하다.\",\n",
    "        category=\"recipe\",\n",
    "        metadata={\"difficulty\": \"medium\", \"prep_time\": \"3분\"}\n",
    "    ),\n",
    "    DocumentChunk(\n",
    "        id=\"recipe_003\",\n",
    "        content=\"카푸치노 레시피: 에스프레소 샷 1개, 스팀 밀크 60ml, 우유 거품 60ml를 순서대로 층을 이루어 넣는다. 거품은 미세하고 벨벳 같은 질감이 중요하다.\",\n",
    "        category=\"recipe\",\n",
    "        metadata={\"difficulty\": \"hard\", \"prep_time\": \"4분\"}\n",
    "    )\n",
    "]\n",
    "\n",
    "# 가격 및 프로모션 정보 지식 베이스\n",
    "PRICE_KNOWLEDGE = [\n",
    "    DocumentChunk(\n",
    "        id=\"price_001\",\n",
    "        content=\"아메리카노 가격: HOT 4,500원, ICE 5,000원. 사이즈 업그레이드 시 각각 500원 추가된다.\",\n",
    "        category=\"price\",\n",
    "        metadata={\"currency\": \"KRW\"}\n",
    "    ),\n",
    "    DocumentChunk(\n",
    "        id=\"price_002\",\n",
    "        content=\"카페라떼와 카푸치노 가격: HOT 5,000원, ICE 5,500원. 두 음료 모두 동일한 가격이다.\",\n",
    "        category=\"price\",\n",
    "        metadata={\"currency\": \"KRW\"}\n",
    "    ),\n",
    "    DocumentChunk(\n",
    "        id=\"price_003\",\n",
    "        content=\"이번 주 프로모션: 오후 2시~5시 사이 아메리카노 구매 시 20% 할인. 중복 할인은 불가능하다.\",\n",
    "        category=\"price\",\n",
    "        metadata={\"promotion_type\": \"time_based\", \"valid_until\": \"2025-10-31\"}\n",
    "    ),\n",
    "    DocumentChunk(\n",
    "        id=\"price_004\",\n",
    "        content=\"녹차라떼 가격: HOT 5,500원, ICE 6,000원. 프리미엄 녹차를 사용하여 다른 라떼보다 가격이 높다.\",\n",
    "        category=\"price\",\n",
    "        metadata={\"currency\": \"KRW\"}\n",
    "    )\n",
    "]\n",
    "\n",
    "# 전체 지식 베이스 통합\n",
    "ALL_KNOWLEDGE = MENU_KNOWLEDGE + RECIPE_KNOWLEDGE + PRICE_KNOWLEDGE\n",
    "\n",
    "print(f\"총 {len(ALL_KNOWLEDGE)}개의 문서 청크가 로드되었다.\")\n",
    "print(f\"메뉴 정보: {len(MENU_KNOWLEDGE)}개\")\n",
    "print(f\"레시피 정보: {len(RECIPE_KNOWLEDGE)}개\")\n",
    "print(f\"가격 정보: {len(PRICE_KNOWLEDGE)}개\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Memory 시스템 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대화 메모리가 초기화되었다.\n"
     ]
    }
   ],
   "source": [
    "class ConversationMemory:\n",
    "    \"\"\"대화 이력을 관리하는 메모리 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self, max_history: int = 10):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            max_history: 저장할 최대 대화 수 (메모리 관리를 위해 제한)\n",
    "        \"\"\"\n",
    "        self.messages: List[ConversationMessage] = []\n",
    "        self.max_history = max_history\n",
    "    \n",
    "    def add_message(self, role: str, content: str, metadata: Dict = None):\n",
    "        \"\"\"새로운 메시지를 메모리에 추가한다\"\"\"\n",
    "        message = ConversationMessage(\n",
    "            role=role,\n",
    "            content=content,\n",
    "            metadata=metadata or {}\n",
    "        )\n",
    "        self.messages.append(message)\n",
    "        \n",
    "        # 최대 이력 수를 초과하면 오래된 메시지부터 제거한다\n",
    "        if len(self.messages) > self.max_history:\n",
    "            self.messages = self.messages[-self.max_history:]\n",
    "    \n",
    "    def get_context(self, include_system: bool = True) -> List[Dict]:\n",
    "        \"\"\"OpenAI API 형식으로 대화 이력을 반환한다\"\"\"\n",
    "        context = []\n",
    "        for msg in self.messages:\n",
    "            if msg.role == \"system\" and not include_system:\n",
    "                continue\n",
    "            context.append({\n",
    "                \"role\": msg.role,\n",
    "                \"content\": msg.content\n",
    "            })\n",
    "        return context\n",
    "    \n",
    "    def clear(self):\n",
    "        \"\"\"모든 대화 이력을 삭제한다\"\"\"\n",
    "        self.messages = []\n",
    "    \n",
    "    def get_summary(self) -> str:\n",
    "        \"\"\"현재까지의 대화를 요약한다\"\"\"\n",
    "        if not self.messages:\n",
    "            return \"대화 이력이 없다.\"\n",
    "        \n",
    "        user_messages = [m for m in self.messages if m.role == \"user\"]\n",
    "        assistant_messages = [m for m in self.messages if m.role == \"assistant\"]\n",
    "        \n",
    "        return f\"총 {len(self.messages)}개의 메시지 (사용자: {len(user_messages)}, 에이전트: {len(assistant_messages)})\"\n",
    "\n",
    "# 메모리 인스턴스 생성\n",
    "memory = ConversationMemory(max_history=10)\n",
    "print(\"대화 메모리가 초기화되었다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. RAG 검색 엔진 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 임베딩을 생성하는 중...\n",
      "11개 문서의 임베딩이 생성되었다.\n"
     ]
    }
   ],
   "source": [
    "class RAGEngine:\n",
    "    \"\"\"RAG 검색 엔진 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self, documents: List[DocumentChunk]):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            documents: 검색할 문서 청크 리스트\n",
    "        \"\"\"\n",
    "        self.documents = documents\n",
    "        self.embeddings_cache = {}\n",
    "        # 모든 문서에 대한 임베딩을 미리 생성한다\n",
    "        self._initialize_embeddings()\n",
    "    \n",
    "    def _get_embedding(self, text: str) -> List[float]:\n",
    "        \"\"\"텍스트의 임베딩 벡터를 생성한다\"\"\"\n",
    "        # 캐시 확인\n",
    "        if text in self.embeddings_cache:\n",
    "            return self.embeddings_cache[text]\n",
    "        \n",
    "        # OpenAI 임베딩 API 호출\n",
    "        response = client.embeddings.create(\n",
    "            model=\"text-embedding-3-small\",\n",
    "            input=text\n",
    "        )\n",
    "        embedding = response.data[0].embedding\n",
    "        \n",
    "        # 캐시에 저장\n",
    "        self.embeddings_cache[text] = embedding\n",
    "        return embedding\n",
    "    \n",
    "    def _initialize_embeddings(self):\n",
    "        \"\"\"모든 문서에 대한 임베딩을 초기화한다\"\"\"\n",
    "        print(\"문서 임베딩을 생성하는 중...\")\n",
    "        for doc in self.documents:\n",
    "            doc.embedding = self._get_embedding(doc.content)\n",
    "        print(f\"{len(self.documents)}개 문서의 임베딩이 생성되었다.\")\n",
    "    \n",
    "    def search(self, query: str, category: Optional[str] = None, top_k: int = 3) -> RetrievalResult:\n",
    "        \"\"\"\n",
    "        쿼리와 가장 유사한 문서를 검색한다\n",
    "        \n",
    "        Args:\n",
    "            query: 검색 쿼리\n",
    "            category: 특정 카테고리로 필터링 (None이면 전체 검색)\n",
    "            top_k: 반환할 상위 문서 개수\n",
    "        \n",
    "        Returns:\n",
    "            검색 결과를 담은 RetrievalResult 객체\n",
    "        \"\"\"\n",
    "        # 쿼리 임베딩 생성\n",
    "        query_embedding = self._get_embedding(query)\n",
    "        query_vector = np.array(query_embedding).reshape(1, -1)\n",
    "        \n",
    "        # 카테고리 필터링\n",
    "        candidate_docs = self.documents\n",
    "        if category:\n",
    "            candidate_docs = [doc for doc in self.documents if doc.category == category]\n",
    "        \n",
    "        # 유사도 계산\n",
    "        doc_vectors = np.array([doc.embedding for doc in candidate_docs])\n",
    "        similarities = cosine_similarity(query_vector, doc_vectors)[0]\n",
    "        \n",
    "        # 상위 k개 문서 선택\n",
    "        top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "        top_docs = [candidate_docs[i] for i in top_indices]\n",
    "        top_scores = [float(similarities[i]) for i in top_indices]\n",
    "        \n",
    "        return RetrievalResult(\n",
    "            chunks=top_docs,\n",
    "            scores=top_scores,\n",
    "            query=query\n",
    "        )\n",
    "\n",
    "# RAG 엔진 인스턴스 생성\n",
    "rag_engine = RAGEngine(ALL_KNOWLEDGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Function Calling & Tool 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 3개의 도구가 정의되었다.\n"
     ]
    }
   ],
   "source": [
    "# Function Calling을 위한 도구 정의\n",
    "TOOLS = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"search_menu_info\",\n",
    "            \"description\": \"메뉴 정보를 검색한다. 커피나 음료의 종류, 특징, 구성 요소에 대한 질문에 사용한다.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"검색할 메뉴 관련 질문\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"query\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"search_recipe_info\",\n",
    "            \"description\": \"레시피 정보를 검색한다. 음료 제조 방법, 재료, 조리 과정에 대한 질문에 사용한다.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"검색할 레시피 관련 질문\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"query\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"search_price_info\",\n",
    "            \"description\": \"가격 및 프로모션 정보를 검색한다. 가격, 할인, 이벤트에 대한 질문에 사용한다.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"검색할 가격/프로모션 관련 질문\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"query\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# 도구 실행 함수 매핑\n",
    "TOOL_FUNCTIONS = {\n",
    "    \"search_menu_info\": lambda query: rag_engine.search(query, category=\"menu\", top_k=2),\n",
    "    \"search_recipe_info\": lambda query: rag_engine.search(query, category=\"recipe\", top_k=2),\n",
    "    \"search_price_info\": lambda query: rag_engine.search(query, category=\"price\", top_k=2)\n",
    "}\n",
    "\n",
    "print(f\"총 {len(TOOLS)}개의 도구가 정의되었다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Validation 시스템 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 시스템이 초기화되었다.\n"
     ]
    }
   ],
   "source": [
    "class ValidationSystem:\n",
    "    \"\"\"답변 검증 시스템 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self, min_relevance_score: float = 0.5, min_confidence: float = 0.6):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            min_relevance_score: 검색 결과의 최소 유사도 점수\n",
    "            min_confidence: 답변의 최소 신뢰도\n",
    "        \"\"\"\n",
    "        self.min_relevance_score = min_relevance_score\n",
    "        self.min_confidence = min_confidence\n",
    "    \n",
    "    def validate_retrieval(self, result: RetrievalResult) -> tuple[bool, str]:\n",
    "        \"\"\"\n",
    "        검색 결과의 유효성을 검증한다\n",
    "        \n",
    "        Returns:\n",
    "            (검증 통과 여부, 검증 메시지)\n",
    "        \"\"\"\n",
    "        # 검색 결과가 없는 경우\n",
    "        if not result.chunks:\n",
    "            return False, \"검색 결과가 없다\"\n",
    "        \n",
    "        # 최고 유사도 점수 확인\n",
    "        max_score = max(result.scores)\n",
    "        if max_score < self.min_relevance_score:\n",
    "            return False, f\"검색 결과의 관련성이 낮다 (최고 점수: {max_score:.2f})\"\n",
    "        \n",
    "        return True, \"검색 결과가 유효하다\"\n",
    "    \n",
    "    def validate_answer(self, answer: str, retrieval_result: RetrievalResult) -> tuple[bool, str]:\n",
    "        \"\"\"\n",
    "        생성된 답변의 유효성을 검증한다\n",
    "        \n",
    "        Returns:\n",
    "            (검증 통과 여부, 검증 메시지)\n",
    "        \"\"\"\n",
    "        # 답변이 비어있는 경우\n",
    "        if not answer or len(answer.strip()) < 10:\n",
    "            return False, \"답변이 너무 짧거나 비어있다\"\n",
    "        \n",
    "        # 답변이 검색된 내용을 포함하는지 확인\n",
    "        # 실제로는 더 정교한 검증이 필요하지만, 여기서는 간단히 키워드 포함 여부만 확인한다\n",
    "        answer_lower = answer.lower()\n",
    "        has_relevant_content = False\n",
    "        \n",
    "        for chunk in retrieval_result.chunks:\n",
    "            # 검색된 문서의 주요 키워드가 답변에 포함되어 있는지 확인\n",
    "            words = chunk.content.lower().split()\n",
    "            relevant_words = [w for w in words if len(w) > 2][:5]\n",
    "            if any(word in answer_lower for word in relevant_words):\n",
    "                has_relevant_content = True\n",
    "                break\n",
    "        \n",
    "        if not has_relevant_content:\n",
    "            return False, \"답변이 검색 결과와 관련이 없다\"\n",
    "        \n",
    "        return True, \"답변이 유효하다\"\n",
    "    \n",
    "    def calculate_confidence(self, retrieval_result: RetrievalResult) -> float:\n",
    "        \"\"\"\n",
    "        검색 결과를 바탕으로 신뢰도를 계산한다\n",
    "        \n",
    "        Returns:\n",
    "            0.0 ~ 1.0 사이의 신뢰도 점수\n",
    "        \"\"\"\n",
    "        if not retrieval_result.scores:\n",
    "            return 0.0\n",
    "        \n",
    "        # 상위 2개 점수의 평균을 신뢰도로 사용\n",
    "        top_scores = sorted(retrieval_result.scores, reverse=True)[:2]\n",
    "        confidence = sum(top_scores) / len(top_scores)\n",
    "        \n",
    "        return min(confidence, 1.0)\n",
    "\n",
    "# 검증 시스템 인스턴스 생성\n",
    "validator = ValidationSystem(min_relevance_score=0.5, min_confidence=0.6)\n",
    "print(\"검증 시스템이 초기화되었다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Recovery 메커니즘 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "복구 시스템이 초기화되었다.\n"
     ]
    }
   ],
   "source": [
    "class RecoverySystem:\n",
    "    \"\"\"복구 메커니즘 시스템 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self, rag_engine: RAGEngine):\n",
    "        self.rag_engine = rag_engine\n",
    "        self.recovery_attempts = 0\n",
    "        self.max_attempts = 2\n",
    "    \n",
    "    def attempt_broader_search(self, original_query: str, failed_category: str) -> Optional[RetrievalResult]:\n",
    "        \"\"\"\n",
    "        특정 카테고리 검색이 실패했을 때 전체 카테고리에서 재검색을 시도한다\n",
    "        \n",
    "        Args:\n",
    "            original_query: 원본 검색 쿼리\n",
    "            failed_category: 실패한 카테고리\n",
    "        \n",
    "        Returns:\n",
    "            새로운 검색 결과 또는 None\n",
    "        \"\"\"\n",
    "        print(f\"Recovery: {failed_category} 카테고리에서 실패하여 전체 검색을 시도한다.\")\n",
    "        \n",
    "        # 전체 카테고리에서 검색\n",
    "        result = self.rag_engine.search(original_query, category=None, top_k=3)\n",
    "        \n",
    "        return result if result.chunks else None\n",
    "    \n",
    "    def reformulate_query(self, original_query: str) -> str:\n",
    "        \"\"\"\n",
    "        검색 쿼리를 재구성하여 더 나은 결과를 얻는다\n",
    "        \n",
    "        Args:\n",
    "            original_query: 원본 검색 쿼리\n",
    "        \n",
    "        Returns:\n",
    "            재구성된 쿼리\n",
    "        \"\"\"\n",
    "        print(\"Recovery: 쿼리를 재구성한다.\")\n",
    "        \n",
    "        # LLM을 사용하여 쿼리를 더 구체적으로 재구성한다\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"사용자의 질문을 커피 메뉴, 레시피, 가격에 관한 더 구체적인 검색 쿼리로 변환하라. 핵심 키워드를 포함하여 20자 이내로 작성하라.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": original_query\n",
    "                }\n",
    "            ],\n",
    "            temperature=0.3\n",
    "        )\n",
    "        \n",
    "        reformulated = response.choices[0].message.content.strip()\n",
    "        print(f\"재구성된 쿼리: {reformulated}\")\n",
    "        \n",
    "        return reformulated\n",
    "    \n",
    "    def generate_fallback_answer(self, query: str) -> str:\n",
    "        \"\"\"\n",
    "        모든 복구 시도가 실패했을 때 대체 답변을 생성한다\n",
    "        \n",
    "        Args:\n",
    "            query: 원본 질문\n",
    "        \n",
    "        Returns:\n",
    "            대체 답변\n",
    "        \"\"\"\n",
    "        return f\"죄송하지만 '{query}'에 대한 정확한 정보를 찾지 못했다. 메뉴판을 확인하시거나 직원에게 문의해 주시기 바란다.\"\n",
    "    \n",
    "    def reset_attempts(self):\n",
    "        \"\"\"복구 시도 카운터를 초기화한다\"\"\"\n",
    "        self.recovery_attempts = 0\n",
    "\n",
    "# 복구 시스템 인스턴스 생성\n",
    "recovery_system = RecoverySystem(rag_engine)\n",
    "print(\"복구 시스템이 초기화되었다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feedback 시스템 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "피드백 시스템이 초기화되었다.\n"
     ]
    }
   ],
   "source": [
    "class FeedbackSystem:\n",
    "    \"\"\"피드백 시스템 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.feedback_history = []\n",
    "    \n",
    "    def evaluate_answer(self, query: str, answer: str, retrieval_result: RetrievalResult) -> float:\n",
    "        \"\"\"\n",
    "        LLM을 사용하여 답변의 품질을 평가한다\n",
    "        \n",
    "        Args:\n",
    "            query: 사용자 질문\n",
    "            answer: 생성된 답변\n",
    "            retrieval_result: 검색 결과\n",
    "        \n",
    "        Returns:\n",
    "            0.0 ~ 1.0 사이의 평가 점수\n",
    "        \"\"\"\n",
    "        # 참조 문서 내용 추출\n",
    "        reference_texts = \"\\n\".join([chunk.content for chunk in retrieval_result.chunks[:2]])\n",
    "        \n",
    "        # LLM을 사용한 답변 평가\n",
    "        evaluation_prompt = f\"\"\"\n",
    "다음 커피 키오스크 질문과 답변을 평가하라.\n",
    "\n",
    "질문: {query}\n",
    "\n",
    "답변: {answer}\n",
    "\n",
    "참조 자료:\n",
    "{reference_texts}\n",
    "\n",
    "평가 기준:\n",
    "1. 답변이 질문에 직접적으로 대응하는가?\n",
    "2. 답변이 참조 자료의 내용과 일치하는가?\n",
    "3. 답변이 명확하고 이해하기 쉬운가?\n",
    "4. 답변이 커피 키오스크 맥락에 적합한가?\n",
    "\n",
    "0.0부터 1.0 사이의 점수만 출력하라. (예: 0.85)\n",
    "\"\"\"\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"당신은 답변 품질을 평가하는 전문가다. 숫자 점수만 반환하라.\"},\n",
    "                {\"role\": \"user\", \"content\": evaluation_prompt}\n",
    "            ],\n",
    "            temperature=0.1\n",
    "        )\n",
    "        \n",
    "        score_text = response.choices[0].message.content.strip()\n",
    "        score = float(score_text)\n",
    "        score = max(0.0, min(1.0, score))\n",
    "        \n",
    "        # 피드백 기록 저장\n",
    "        self.feedback_history.append({\n",
    "            \"query\": query,\n",
    "            \"answer\": answer,\n",
    "            \"score\": score,\n",
    "            \"timestamp\": datetime.now()\n",
    "        })\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    def get_improvement_suggestions(self, low_score_threshold: float = 0.6) -> List[str]:\n",
    "        \"\"\"\n",
    "        낮은 점수를 받은 답변들을 분석하여 개선 제안을 생성한다\n",
    "        \n",
    "        Args:\n",
    "            low_score_threshold: 낮은 점수로 간주할 임계값\n",
    "        \n",
    "        Returns:\n",
    "            개선 제안 리스트\n",
    "        \"\"\"\n",
    "        low_score_items = [item for item in self.feedback_history if item[\"score\"] < low_score_threshold]\n",
    "        \n",
    "        if not low_score_items:\n",
    "            return [\"모든 답변이 양호한 품질을 유지하고 있다.\"]\n",
    "        \n",
    "        suggestions = [\n",
    "            f\"{len(low_score_items)}개의 답변이 개선이 필요하다.\",\n",
    "            \"지식 베이스에 더 많은 정보를 추가하는 것을 고려하라.\",\n",
    "            \"검색 쿼리 재구성 로직을 개선하라.\"\n",
    "        ]\n",
    "        \n",
    "        return suggestions\n",
    "    \n",
    "    def get_average_score(self) -> float:\n",
    "        \"\"\"전체 답변의 평균 점수를 계산한다\"\"\"\n",
    "        if not self.feedback_history:\n",
    "            return 0.0\n",
    "        return sum(item[\"score\"] for item in self.feedback_history) / len(self.feedback_history)\n",
    "\n",
    "# 피드백 시스템 인스턴스 생성\n",
    "feedback_system = FeedbackSystem()\n",
    "print(\"피드백 시스템이 초기화되었다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Router RAG Agent 통합 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Router RAG Agent가 초기화되었다.\n"
     ]
    }
   ],
   "source": [
    "class RouterRAGAgent:\n",
    "    \"\"\"Router RAG Agent 메인 클래스\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        rag_engine: RAGEngine,\n",
    "        memory: ConversationMemory,\n",
    "        validator: ValidationSystem,\n",
    "        recovery: RecoverySystem,\n",
    "        feedback: FeedbackSystem\n",
    "    ):\n",
    "        self.rag_engine = rag_engine\n",
    "        self.memory = memory\n",
    "        self.validator = validator\n",
    "        self.recovery = recovery\n",
    "        self.feedback = feedback\n",
    "        \n",
    "        # 시스템 프롬프트를 메모리에 추가\n",
    "        self.memory.add_message(\n",
    "            \"system\",\n",
    "            \"당신은 커피 키오스크의 친절한 주문 도우미다. 고객의 질문에 정확하고 친절하게 답변하라.\"\n",
    "        )\n",
    "    \n",
    "    def route_and_retrieve(self, user_query: str) -> tuple[RetrievalResult, str]:\n",
    "        \"\"\"\n",
    "        사용자 질문을 라우팅하고 관련 정보를 검색한다\n",
    "        \n",
    "        Returns:\n",
    "            (검색 결과, 사용된 라우트)\n",
    "        \"\"\"\n",
    "        # Function Calling을 사용하여 적절한 도구 선택\n",
    "        messages = self.memory.get_context()\n",
    "        messages.append({\"role\": \"user\", \"content\": user_query})\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            tools=TOOLS,\n",
    "            tool_choice=\"auto\"\n",
    "        )\n",
    "        \n",
    "        # 도구 호출 여부 확인\n",
    "        response_message = response.choices[0].message\n",
    "        \n",
    "        if response_message.tool_calls:\n",
    "            # 첫 번째 도구 호출 처리\n",
    "            tool_call = response_message.tool_calls[0]\n",
    "            function_name = tool_call.function.name\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            \n",
    "            print(f\"선택된 라우트: {function_name}\")\n",
    "            print(f\"검색 쿼리: {function_args['query']}\")\n",
    "            \n",
    "            # 해당 도구 실행\n",
    "            retrieval_result = TOOL_FUNCTIONS[function_name](function_args[\"query\"])\n",
    "            \n",
    "            return retrieval_result, function_name\n",
    "        \n",
    "        # 도구를 선택하지 않은 경우 기본 전체 검색\n",
    "        print(\"기본 라우트: 전체 검색\")\n",
    "        retrieval_result = self.rag_engine.search(user_query, category=None, top_k=3)\n",
    "        return retrieval_result, \"general_search\"\n",
    "    \n",
    "    def generate_answer(self, user_query: str, retrieval_result: RetrievalResult) -> str:\n",
    "        \"\"\"\n",
    "        검색 결과를 바탕으로 최종 답변을 생성한다\n",
    "        \n",
    "        Args:\n",
    "            user_query: 사용자 질문\n",
    "            retrieval_result: RAG 검색 결과\n",
    "        \n",
    "        Returns:\n",
    "            생성된 답변\n",
    "        \"\"\"\n",
    "        # 검색된 문서를 컨텍스트로 구성\n",
    "        context_parts = []\n",
    "        for i, chunk in enumerate(retrieval_result.chunks[:3]):\n",
    "            context_parts.append(f\"[참조 {i+1}] {chunk.content}\")\n",
    "        context = \"\\n\\n\".join(context_parts)\n",
    "        \n",
    "        # 답변 생성 프롬프트\n",
    "        generation_prompt = f\"\"\"\n",
    "다음 참조 정보를 바탕으로 고객의 질문에 답변하라.\n",
    "\n",
    "고객 질문: {user_query}\n",
    "\n",
    "참조 정보:\n",
    "{context}\n",
    "\n",
    "답변 작성 지침:\n",
    "1. 참조 정보의 내용만을 사용하여 답변하라\n",
    "2. 친절하고 명확한 어조로 작성하라\n",
    "3. 불필요한 정보는 제외하라\n",
    "4. 2-3문장으로 간결하게 답변하라\n",
    "\"\"\"\n",
    "        \n",
    "        messages = self.memory.get_context(include_system=True)\n",
    "        messages.append({\"role\": \"user\", \"content\": generation_prompt})\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            temperature=0.3\n",
    "        )\n",
    "        \n",
    "        answer = response.choices[0].message.content.strip()\n",
    "        return answer\n",
    "    \n",
    "    def process_query(self, user_query: str) -> AgentResponse:\n",
    "        \"\"\"\n",
    "        사용자 질문을 처리하고 최종 응답을 생성한다\n",
    "        \n",
    "        Args:\n",
    "            user_query: 사용자 질문\n",
    "        \n",
    "        Returns:\n",
    "            AgentResponse 객체\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"사용자 질문: {user_query}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # 1. 사용자 메시지를 메모리에 추가\n",
    "        self.memory.add_message(\"user\", user_query)\n",
    "        \n",
    "        # 2. 라우팅 및 검색\n",
    "        retrieval_result, route_used = self.route_and_retrieve(user_query)\n",
    "        \n",
    "        # 3. 검색 결과 검증\n",
    "        is_valid, validation_message = self.validator.validate_retrieval(retrieval_result)\n",
    "        print(f\"검색 검증: {validation_message}\")\n",
    "        \n",
    "        # 4. 검증 실패 시 Recovery 메커니즘 실행\n",
    "        if not is_valid:\n",
    "            print(\"Recovery 프로세스 시작...\")\n",
    "            \n",
    "            # 전체 검색 시도\n",
    "            retrieval_result = self.recovery.attempt_broader_search(user_query, route_used)\n",
    "            \n",
    "            # 여전히 실패하면 쿼리 재구성\n",
    "            if retrieval_result is None or not retrieval_result.chunks:\n",
    "                reformulated_query = self.recovery.reformulate_query(user_query)\n",
    "                retrieval_result, route_used = self.route_and_retrieve(reformulated_query)\n",
    "            \n",
    "            # 모든 시도 실패 시 대체 답변\n",
    "            if retrieval_result is None or not retrieval_result.chunks:\n",
    "                answer = self.recovery.generate_fallback_answer(user_query)\n",
    "                self.memory.add_message(\"assistant\", answer)\n",
    "                \n",
    "                return AgentResponse(\n",
    "                    answer=answer,\n",
    "                    route_used=route_used,\n",
    "                    sources=[],\n",
    "                    confidence=0.0,\n",
    "                    validation_passed=False,\n",
    "                    feedback_score=None\n",
    "                )\n",
    "        \n",
    "        # 5. 답변 생성\n",
    "        answer = self.generate_answer(user_query, retrieval_result)\n",
    "        print(f\"\\n생성된 답변: {answer}\")\n",
    "        \n",
    "        # 6. 답변 검증\n",
    "        answer_valid, answer_validation_msg = self.validator.validate_answer(answer, retrieval_result)\n",
    "        print(f\"답변 검증: {answer_validation_msg}\")\n",
    "        \n",
    "        # 7. 신뢰도 계산\n",
    "        confidence = self.validator.calculate_confidence(retrieval_result)\n",
    "        print(f\"신뢰도: {confidence:.2f}\")\n",
    "        \n",
    "        # 8. 피드백 평가\n",
    "        feedback_score = self.feedback.evaluate_answer(user_query, answer, retrieval_result)\n",
    "        print(f\"피드백 점수: {feedback_score:.2f}\")\n",
    "        \n",
    "        # 9. 답변을 메모리에 추가\n",
    "        self.memory.add_message(\"assistant\", answer, metadata={\n",
    "            \"route\": route_used,\n",
    "            \"confidence\": confidence,\n",
    "            \"feedback_score\": feedback_score\n",
    "        })\n",
    "        \n",
    "        # 10. 최종 응답 생성\n",
    "        sources = [chunk.id for chunk in retrieval_result.chunks[:3]]\n",
    "        \n",
    "        return AgentResponse(\n",
    "            answer=answer,\n",
    "            route_used=route_used,\n",
    "            sources=sources,\n",
    "            confidence=confidence,\n",
    "            validation_passed=answer_valid,\n",
    "            feedback_score=feedback_score\n",
    "        )\n",
    "\n",
    "# Router RAG Agent 인스턴스 생성\n",
    "agent = RouterRAGAgent(\n",
    "    rag_engine=rag_engine,\n",
    "    memory=memory,\n",
    "    validator=validator,\n",
    "    recovery=recovery_system,\n",
    "    feedback=feedback_system\n",
    ")\n",
    "\n",
    "print(\"\\nRouter RAG Agent가 초기화되었다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 에이전트 테스트\n",
    "\n",
    "다양한 시나리오로 Router RAG Agent를 테스트한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "사용자 질문: 아메리카노는 어떤 커피인가요?\n",
      "============================================================\n",
      "선택된 라우트: search_menu_info\n",
      "검색 쿼리: 아메리카노\n",
      "검색 검증: 검색 결과가 유효하다\n",
      "\n",
      "생성된 답변: 아메리카노는 에스프레소에 물을 추가한 커피로, 진하고 깊은 맛이 특징입니다. HOT과 ICE 옵션이 있어 취향에 맞게 선택하실 수 있습니다.\n",
      "답변 검증: 답변이 유효하다\n",
      "신뢰도: 0.35\n",
      "피드백 점수: 1.00\n",
      "\n",
      "최종 응답:\n",
      "  - 답변: 아메리카노는 에스프레소에 물을 추가한 커피로, 진하고 깊은 맛이 특징입니다. HOT과 ICE 옵션이 있어 취향에 맞게 선택하실 수 있습니다.\n",
      "  - 사용된 라우트: search_menu_info\n",
      "  - 참조 소스: menu_001, menu_003\n",
      "  - 신뢰도: 0.35\n",
      "  - 검증 통과: True\n",
      "  - 피드백 점수: 1.00\n",
      "\n",
      "\n",
      "============================================================\n",
      "사용자 질문: 카페라떼 만드는 방법을 알려주세요\n",
      "============================================================\n",
      "선택된 라우트: search_recipe_info\n",
      "검색 쿼리: 카페라떼 만드는 방법\n",
      "검색 검증: 검색 결과가 유효하다\n",
      "\n",
      "생성된 답변: 카페라떼를 만들려면 먼저 에스프레소 샷 2개를 추출합니다. 그 다음, 우유 200ml를 스티밍하여 65-70도 정도로 데운 후, 부드럽게 에스프레소에 붓습니다. 이렇게 하면 맛있는 카페라떼가 완성됩니다!\n",
      "답변 검증: 답변이 유효하다\n",
      "신뢰도: 0.39\n",
      "피드백 점수: 1.00\n",
      "\n",
      "최종 응답:\n",
      "  - 답변: 카페라떼를 만들려면 먼저 에스프레소 샷 2개를 추출합니다. 그 다음, 우유 200ml를 스티밍하여 65-70도 정도로 데운 후, 부드럽게 에스프레소에 붓습니다. 이렇게 하면 맛있는 카페라떼가 완성됩니다!\n",
      "  - 사용된 라우트: search_recipe_info\n",
      "  - 참조 소스: recipe_002, recipe_003\n",
      "  - 신뢰도: 0.39\n",
      "  - 검증 통과: True\n",
      "  - 피드백 점수: 1.00\n",
      "\n",
      "\n",
      "============================================================\n",
      "사용자 질문: 카푸치노 가격이 얼마인가요?\n",
      "============================================================\n",
      "선택된 라우트: search_price_info\n",
      "검색 쿼리: 카푸치노 가격\n",
      "검색 검증: 검색 결과가 유효하다\n",
      "\n",
      "생성된 답변: 카푸치노의 가격은 HOT 5,000원, ICE 5,500원입니다. 카페라떼와 동일한 가격이니 참고해 주세요!\n",
      "답변 검증: 답변이 유효하다\n",
      "신뢰도: 0.47\n",
      "피드백 점수: 1.00\n",
      "\n",
      "최종 응답:\n",
      "  - 답변: 카푸치노의 가격은 HOT 5,000원, ICE 5,500원입니다. 카페라떼와 동일한 가격이니 참고해 주세요!\n",
      "  - 사용된 라우트: search_price_info\n",
      "  - 참조 소스: price_002, price_003\n",
      "  - 신뢰도: 0.47\n",
      "  - 검증 통과: True\n",
      "  - 피드백 점수: 1.00\n",
      "\n",
      "\n",
      "============================================================\n",
      "사용자 질문: 녹차라떼에는 어떤 재료가 들어가나요?\n",
      "============================================================\n",
      "선택된 라우트: search_menu_info\n",
      "검색 쿼리: 녹차라떼 재료\n",
      "검색 검증: 검색 결과가 유효하다\n",
      "\n",
      "생성된 답변: 녹차라떼는 고품질 녹차 파우더와 우유를 블렌딩한 음료입니다. 녹차의 은은한 향과 우유의 부드러움이 조화롭게 어우러져, 카페인이 적어 부담 없이 즐길 수 있습니다.\n",
      "답변 검증: 답변이 유효하다\n",
      "신뢰도: 0.38\n",
      "피드백 점수: 1.00\n",
      "\n",
      "최종 응답:\n",
      "  - 답변: 녹차라떼는 고품질 녹차 파우더와 우유를 블렌딩한 음료입니다. 녹차의 은은한 향과 우유의 부드러움이 조화롭게 어우러져, 카페인이 적어 부담 없이 즐길 수 있습니다.\n",
      "  - 사용된 라우트: search_menu_info\n",
      "  - 참조 소스: menu_004, menu_002\n",
      "  - 신뢰도: 0.38\n",
      "  - 검증 통과: True\n",
      "  - 피드백 점수: 1.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 테스트 질문 리스트\n",
    "test_queries = [\n",
    "    \"아메리카노는 어떤 커피인가요?\",\n",
    "    \"카페라떼 만드는 방법을 알려주세요\",\n",
    "    \"카푸치노 가격이 얼마인가요?\",\n",
    "    \"녹차라떼에는 어떤 재료가 들어가나요?\"\n",
    "]\n",
    "\n",
    "# 각 질문에 대해 에이전트 실행\n",
    "for query in test_queries:\n",
    "    response = agent.process_query(query)\n",
    "    print(f\"\\n최종 응답:\")\n",
    "    print(f\"  - 답변: {response.answer}\")\n",
    "    print(f\"  - 사용된 라우트: {response.route_used}\")\n",
    "    print(f\"  - 참조 소스: {', '.join(response.sources)}\")\n",
    "    print(f\"  - 신뢰도: {response.confidence:.2f}\")\n",
    "    print(f\"  - 검증 통과: {response.validation_passed}\")\n",
    "    print(f\"  - 피드백 점수: {response.feedback_score:.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 대화형 인터페이스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "커피 키오스크 Router RAG Agent\n",
      "종료하려면 'quit' 또는 'exit'를 입력하세요.\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "고객:  아메리카노 2잔 주문\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "사용자 질문: 아메리카노 2잔 주문\n",
      "============================================================\n",
      "기본 라우트: 전체 검색\n",
      "검색 검증: 검색 결과가 유효하다\n",
      "\n",
      "생성된 답변: 아메리카노 2잔 주문해주셨군요! HOT 아메리카노는 4,500원, ICE 아메리카노는 5,000원입니다. 오후 2시~5시 사이에 주문하시면 20% 할인 혜택도 적용됩니다. 어떤 종류로 드릴까요?\n",
      "답변 검증: 답변이 유효하다\n",
      "신뢰도: 0.53\n",
      "피드백 점수: 0.95\n",
      "\n",
      "에이전트: 아메리카노 2잔 주문해주셨군요! HOT 아메리카노는 4,500원, ICE 아메리카노는 5,000원입니다. 오후 2시~5시 사이에 주문하시면 20% 할인 혜택도 적용됩니다. 어떤 종류로 드릴까요?\n",
      "(신뢰도: 0.53, 피드백: 0.95)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "고객:  아이스 아메리카노\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "사용자 질문: 아이스 아메리카노\n",
      "============================================================\n",
      "선택된 라우트: search_price_info\n",
      "검색 쿼리: 아이스 아메리카노 가격\n",
      "검색 검증: 검색 결과가 유효하다\n",
      "\n",
      "생성된 답변: 아이스 아메리카노는 5,000원입니다. 이번 주 프로모션으로 오후 2시~5시 사이에 구매하시면 20% 할인 혜택을 받으실 수 있습니다. 추가 사이즈 업그레이드 시 500원이 추가됩니다.\n",
      "답변 검증: 답변이 유효하다\n",
      "신뢰도: 0.53\n",
      "피드백 점수: 1.00\n",
      "\n",
      "에이전트: 아이스 아메리카노는 5,000원입니다. 이번 주 프로모션으로 오후 2시~5시 사이에 구매하시면 20% 할인 혜택을 받으실 수 있습니다. 추가 사이즈 업그레이드 시 500원이 추가됩니다.\n",
      "(신뢰도: 0.53, 피드백: 1.00)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "고객:  레귤러 사이즈로\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "사용자 질문: 레귤러 사이즈로\n",
      "============================================================\n",
      "기본 라우트: 전체 검색\n",
      "검색 검증: 검색 결과의 관련성이 낮다 (최고 점수: 0.27)\n",
      "Recovery 프로세스 시작...\n",
      "Recovery: general_search 카테고리에서 실패하여 전체 검색을 시도한다.\n",
      "\n",
      "생성된 답변: 레귤러 사이즈 아이스 아메리카노는 5,000원입니다. 주문해주신 내용으로 준비해드리겠습니다. 감사합니다!\n",
      "답변 검증: 답변이 유효하다\n",
      "신뢰도: 0.26\n",
      "피드백 점수: 1.00\n",
      "\n",
      "에이전트: 레귤러 사이즈 아이스 아메리카노는 5,000원입니다. 주문해주신 내용으로 준비해드리겠습니다. 감사합니다!\n",
      "(신뢰도: 0.26, 피드백: 1.00)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "고객:  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "대화를 종료한다.\n"
     ]
    }
   ],
   "source": [
    "def chat_interface():\n",
    "    \"\"\"대화형 인터페이스 함수\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"커피 키오스크 Router RAG Agent\")\n",
    "    print(\"종료하려면 'quit' 또는 'exit'를 입력하세요.\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"\\n고객: \").strip()\n",
    "        \n",
    "        if user_input.lower() in ['quit', 'exit', '종료']:\n",
    "            print(\"\\n대화를 종료한다.\")\n",
    "            break\n",
    "        \n",
    "        if not user_input:\n",
    "            continue\n",
    "        \n",
    "        response = agent.process_query(user_input)\n",
    "        print(f\"\\n에이전트: {response.answer}\")\n",
    "        print(f\"(신뢰도: {response.confidence:.2f}, 피드백: {response.feedback_score:.2f})\")\n",
    "\n",
    "# 대화 시작 (주석을 제거하여 실행)\n",
    "chat_interface()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. 성능 분석 및 리포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "성능 분석 리포트\n",
      "============================================================\n",
      "\n",
      "평균 피드백 점수: 0.99\n",
      "\n",
      "개선 제안:\n",
      "  1. 모든 답변이 양호한 품질을 유지하고 있다.\n",
      "\n",
      "대화 메모리 상태: 총 10개의 메시지 (사용자: 5, 에이전트: 5)\n",
      "\n",
      "============================================================\n",
      "튜토리얼 1: Router RAG Agent 완료\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 피드백 시스템 통계\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"성능 분석 리포트\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "avg_score = feedback_system.get_average_score()\n",
    "print(f\"\\n평균 피드백 점수: {avg_score:.2f}\")\n",
    "\n",
    "suggestions = feedback_system.get_improvement_suggestions(low_score_threshold=0.7)\n",
    "print(\"\\n개선 제안:\")\n",
    "for i, suggestion in enumerate(suggestions, 1):\n",
    "    print(f\"  {i}. {suggestion}\")\n",
    "\n",
    "print(f\"\\n대화 메모리 상태: {memory.get_summary()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"튜토리얼 1: Router RAG Agent 완료\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lecture",
   "language": "python",
   "name": "lecture"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
